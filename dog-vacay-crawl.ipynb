{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_datascience": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import sqlite3 as lite\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_datascience": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_datascience": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = {'tx' : \"austin\"\n",
    "          , 'ca' : 'los-angeles'\n",
    "          , 'ga' : 'atlanta'\n",
    "          , 'ma' : 'boston'\n",
    "          , 'nc' : 'charlotte'\n",
    "          , 'tx' : 'dallas'\n",
    "          , 'co' : 'denver'\n",
    "          , 'tx' : 'houston'\n",
    "          , 'fl' : 'miami'\n",
    "          , 'mn' : 'minneapolis'\n",
    "          , 'ny' : 'new-york'\n",
    "          , 'pa' : 'philadelphia'\n",
    "          , 'az' : 'phoenix'\n",
    "          , 'or' : 'portland'\n",
    "          , 'ca' : 'san-francisco'\n",
    "          , 'ca' : 'san-diego'\n",
    "          , 'wa' : 'seattle'\n",
    "          , 'dc' : 'washington'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_datascience": {},
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mn minneapolis\n",
      ".......\n",
      "ma boston\n",
      ".............\n",
      "wa seattle\n",
      ".........\n",
      "tx houston\n",
      "...........\n",
      "ca san-diego\n",
      "...........\n",
      "nc charlotte\n",
      ".......\n",
      "dc washington\n",
      "...........................\n",
      "ny new-york\n",
      "...........................................--------------------\n",
      "pa philadelphia\n",
      "------------\n",
      "ga atlanta\n",
      "------------\n",
      "co denver\n",
      "-----------\n",
      "az phoenix\n",
      "---------\n",
      "fl miami\n",
      "---------\n",
      "or portland\n",
      "----------"
     ]
    }
   ],
   "source": [
    "# CRAWL ALL THE PAGES OF INTERST\n",
    "\n",
    "datadir = 'crawl/'\n",
    "if not(os.path.isdir(datadir)):\n",
    "    os.makedirs(datadir)\n",
    "\n",
    "for k,v in cities.iteritems():\n",
    "    running = True\n",
    "    page = 1\n",
    "    print ''\n",
    "    print k,v\n",
    "    while running:\n",
    "        url = \"https://dogvacay.com/dog-boarding--\" + k + \"--\" + v + \"?p=\"+str(page)\n",
    "        filename = datadir + k + '-' + v + '-' + str(page) + '.htm'\n",
    "        if not(os.path.isfile(filename)):\n",
    "            sys.stdout.write('-')\n",
    "            r = requests.get(url, headers=headers)\n",
    "            time.sleep(1)\n",
    "            f = open(filename, 'w')\n",
    "            f.write(r.text.encode('ascii', 'replace'))\n",
    "            f.close()\n",
    "            data = r.text\n",
    "        else:\n",
    "            sys.stdout.write('.')\n",
    "            f = open(filename, 'r')\n",
    "            data = f.read()\n",
    "            f.close()\n",
    "        soup = BeautifulSoup(data)\n",
    "        pagination_links = soup.findAll('a', {'class': 'pagination-link'})\n",
    "        running = False\n",
    "        for pl in pagination_links:\n",
    "            if pl.text.find('Next') == 0:\n",
    "                running = True\n",
    "        page+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_datascience": {},
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: crawl/az-phoenix-1.htm\n",
      "Processing: crawl/az-phoenix-2.htm\n",
      "Processing: crawl/az-phoenix-3.htm\n",
      "Processing: crawl/az-phoenix-4.htm\n",
      "Processing: crawl/az-phoenix-5.htm\n",
      "Processing: crawl/az-phoenix-6.htm\n",
      "Processing: crawl/az-phoenix-7.htm\n",
      "Processing: crawl/az-phoenix-8.htm\n",
      "Processing: crawl/az-phoenix-9.htm\n",
      "Processing: crawl/ca-san-diego-1.htm\n",
      "Processing: crawl/ca-san-diego-10.htm\n",
      "Processing: crawl/ca-san-diego-11.htm\n",
      "Processing: crawl/ca-san-diego-2.htm\n",
      "Processing: crawl/ca-san-diego-3.htm\n",
      "Processing: crawl/ca-san-diego-4.htm\n",
      "Processing: crawl/ca-san-diego-5.htm\n",
      "Processing: crawl/ca-san-diego-6.htm\n",
      "Processing: crawl/ca-san-diego-7.htm\n",
      "Processing: crawl/ca-san-diego-8.htm\n",
      "Processing: crawl/ca-san-diego-9.htm\n",
      "Processing: crawl/co-denver-1.htm\n",
      "Processing: crawl/co-denver-10.htm\n",
      "Processing: crawl/co-denver-11.htm\n",
      "Processing: crawl/co-denver-2.htm\n",
      "Processing: crawl/co-denver-3.htm\n",
      "Processing: crawl/co-denver-4.htm\n",
      "Processing: crawl/co-denver-5.htm\n",
      "Processing: crawl/co-denver-6.htm\n",
      "Processing: crawl/co-denver-7.htm\n",
      "Processing: crawl/co-denver-8.htm\n",
      "Processing: crawl/co-denver-9.htm\n",
      "Processing: crawl/dc-washington-1.htm\n",
      "Processing: crawl/dc-washington-10.htm\n",
      "Processing: crawl/dc-washington-11.htm\n",
      "Processing: crawl/dc-washington-12.htm\n",
      "Processing: crawl/dc-washington-13.htm\n",
      "Processing: crawl/dc-washington-14.htm\n",
      "Processing: crawl/dc-washington-15.htm\n",
      "Processing: crawl/dc-washington-16.htm\n",
      "Processing: crawl/dc-washington-17.htm\n",
      "Processing: crawl/dc-washington-18.htm\n",
      "Processing: crawl/dc-washington-19.htm\n",
      "Processing: crawl/dc-washington-2.htm\n",
      "Processing: crawl/dc-washington-20.htm\n",
      "Processing: crawl/dc-washington-21.htm\n",
      "Processing: crawl/dc-washington-22.htm\n",
      "Processing: crawl/dc-washington-23.htm\n",
      "Processing: crawl/dc-washington-24.htm\n",
      "Processing: crawl/dc-washington-25.htm\n",
      "Processing: crawl/dc-washington-26.htm\n",
      "Processing: crawl/dc-washington-27.htm\n",
      "Processing: crawl/dc-washington-3.htm\n",
      "Processing: crawl/dc-washington-4.htm\n",
      "Processing: crawl/dc-washington-5.htm\n",
      "Processing: crawl/dc-washington-6.htm\n",
      "Processing: crawl/dc-washington-7.htm\n",
      "Processing: crawl/dc-washington-8.htm\n",
      "Processing: crawl/dc-washington-9.htm\n",
      "Processing: crawl/fl-miami-1.htm\n",
      "Processing: crawl/fl-miami-2.htm\n",
      "Processing: crawl/fl-miami-3.htm\n",
      "Processing: crawl/fl-miami-4.htm\n",
      "Processing: crawl/fl-miami-5.htm\n",
      "Processing: crawl/fl-miami-6.htm\n",
      "Processing: crawl/fl-miami-7.htm\n",
      "Processing: crawl/fl-miami-8.htm\n",
      "Processing: crawl/fl-miami-9.htm\n",
      "Processing: crawl/ga-atlanta-1.htm\n",
      "Processing: crawl/ga-atlanta-10.htm\n",
      "Processing: crawl/ga-atlanta-11.htm\n",
      "Processing: crawl/ga-atlanta-12.htm\n",
      "Processing: crawl/ga-atlanta-2.htm\n",
      "Processing: crawl/ga-atlanta-3.htm\n",
      "Processing: crawl/ga-atlanta-4.htm\n",
      "Processing: crawl/ga-atlanta-5.htm\n",
      "Processing: crawl/ga-atlanta-6.htm\n",
      "Processing: crawl/ga-atlanta-7.htm\n",
      "Processing: crawl/ga-atlanta-8.htm\n",
      "Processing: crawl/ga-atlanta-9.htm\n",
      "Processing: crawl/ma-boston-1.htm\n",
      "Processing: crawl/ma-boston-10.htm\n",
      "Processing: crawl/ma-boston-11.htm\n",
      "Processing: crawl/ma-boston-12.htm\n",
      "Processing: crawl/ma-boston-13.htm\n",
      "Processing: crawl/ma-boston-2.htm\n",
      "Processing: crawl/ma-boston-3.htm\n",
      "Processing: crawl/ma-boston-4.htm\n",
      "Processing: crawl/ma-boston-5.htm\n",
      "Processing: crawl/ma-boston-6.htm\n",
      "Processing: crawl/ma-boston-7.htm\n",
      "Processing: crawl/ma-boston-8.htm\n",
      "Processing: crawl/ma-boston-9.htm\n",
      "Processing: crawl/mn-minneapolis-1.htm\n",
      "Processing: crawl/mn-minneapolis-2.htm\n",
      "Processing: crawl/mn-minneapolis-3.htm\n",
      "Processing: crawl/mn-minneapolis-4.htm\n",
      "Processing: crawl/mn-minneapolis-5.htm\n",
      "Processing: crawl/mn-minneapolis-6.htm\n",
      "Processing: crawl/mn-minneapolis-7.htm\n",
      "Processing: crawl/nc-charlotte-1.htm\n",
      "Processing: crawl/nc-charlotte-2.htm\n",
      "Processing: crawl/nc-charlotte-3.htm\n",
      "Processing: crawl/nc-charlotte-4.htm\n",
      "Processing: crawl/nc-charlotte-5.htm\n",
      "Processing: crawl/nc-charlotte-6.htm\n",
      "Processing: crawl/nc-charlotte-7.htm\n",
      "Processing: crawl/ny-new-york-1.htm\n",
      "Processing: crawl/ny-new-york-10.htm\n",
      "Processing: crawl/ny-new-york-11.htm\n",
      "Processing: crawl/ny-new-york-12.htm\n",
      "Processing: crawl/ny-new-york-13.htm\n",
      "Processing: crawl/ny-new-york-14.htm\n",
      "Processing: crawl/ny-new-york-15.htm\n",
      "Processing: crawl/ny-new-york-16.htm\n",
      "Processing: crawl/ny-new-york-17.htm\n",
      "Processing: crawl/ny-new-york-18.htm\n",
      "Processing: crawl/ny-new-york-19.htm\n",
      "Processing: crawl/ny-new-york-2.htm\n",
      "Processing: crawl/ny-new-york-20.htm\n",
      "Processing: crawl/ny-new-york-21.htm\n",
      "Processing: crawl/ny-new-york-22.htm\n",
      "Processing: crawl/ny-new-york-23.htm\n",
      "Processing: crawl/ny-new-york-24.htm\n",
      "Processing: crawl/ny-new-york-25.htm\n",
      "Processing: crawl/ny-new-york-26.htm\n",
      "Processing: crawl/ny-new-york-27.htm\n",
      "Processing: crawl/ny-new-york-28.htm\n",
      "Processing: crawl/ny-new-york-29.htm\n",
      "Processing: crawl/ny-new-york-3.htm\n",
      "Processing: crawl/ny-new-york-30.htm\n",
      "Processing: crawl/ny-new-york-31.htm\n",
      "Processing: crawl/ny-new-york-32.htm\n",
      "Processing: crawl/ny-new-york-33.htm\n",
      "Processing: crawl/ny-new-york-34.htm\n",
      "Processing: crawl/ny-new-york-35.htm\n",
      "Processing: crawl/ny-new-york-36.htm\n",
      "Processing: crawl/ny-new-york-37.htm\n",
      "Processing: crawl/ny-new-york-38.htm\n",
      "Processing: crawl/ny-new-york-39.htm\n",
      "Processing: crawl/ny-new-york-4.htm\n",
      "Processing: crawl/ny-new-york-40.htm\n",
      "Processing: crawl/ny-new-york-41.htm\n",
      "Processing: crawl/ny-new-york-42.htm\n",
      "Processing: crawl/ny-new-york-43.htm\n",
      "Processing: crawl/ny-new-york-44.htm\n",
      "Processing: crawl/ny-new-york-45.htm\n",
      "Processing: crawl/ny-new-york-46.htm\n",
      "Processing: crawl/ny-new-york-47.htm\n",
      "Processing: crawl/ny-new-york-48.htm\n",
      "Processing: crawl/ny-new-york-49.htm\n",
      "Processing: crawl/ny-new-york-5.htm\n",
      "Processing: crawl/ny-new-york-50.htm\n",
      "Processing: crawl/ny-new-york-51.htm\n",
      "Processing: crawl/ny-new-york-52.htm\n",
      "Processing: crawl/ny-new-york-53.htm\n",
      "Processing: crawl/ny-new-york-54.htm\n",
      "Processing: crawl/ny-new-york-55.htm\n",
      "Processing: crawl/ny-new-york-56.htm\n",
      "Processing: crawl/ny-new-york-57.htm\n",
      "Processing: crawl/ny-new-york-58.htm\n",
      "Processing: crawl/ny-new-york-59.htm\n",
      "Processing: crawl/ny-new-york-6.htm\n",
      "Processing: crawl/ny-new-york-60.htm\n",
      "Processing: crawl/ny-new-york-61.htm\n",
      "Processing: crawl/ny-new-york-62.htm\n",
      "Processing: crawl/ny-new-york-63.htm\n",
      "Processing: crawl/ny-new-york-7.htm\n",
      "Processing: crawl/ny-new-york-8.htm\n",
      "Processing: crawl/ny-new-york-9.htm\n",
      "Processing: crawl/or-portland-1.htm\n",
      "Processing: crawl/or-portland-10.htm\n",
      "Processing: crawl/or-portland-2.htm\n",
      "Processing: crawl/or-portland-3.htm\n",
      "Processing: crawl/or-portland-4.htm\n",
      "Processing: crawl/or-portland-5.htm\n",
      "Processing: crawl/or-portland-6.htm\n",
      "Processing: crawl/or-portland-7.htm\n",
      "Processing: crawl/or-portland-8.htm\n",
      "Processing: crawl/or-portland-9.htm\n",
      "Processing: crawl/pa-philadelphia-1.htm\n",
      "Processing: crawl/pa-philadelphia-10.htm\n",
      "Processing: crawl/pa-philadelphia-11.htm\n",
      "Processing: crawl/pa-philadelphia-12.htm\n",
      "Processing: crawl/pa-philadelphia-2.htm\n",
      "Processing: crawl/pa-philadelphia-3.htm\n",
      "Processing: crawl/pa-philadelphia-4.htm\n",
      "Processing: crawl/pa-philadelphia-5.htm\n",
      "Processing: crawl/pa-philadelphia-6.htm\n",
      "Processing: crawl/pa-philadelphia-7.htm\n",
      "Processing: crawl/pa-philadelphia-8.htm\n",
      "Processing: crawl/pa-philadelphia-9.htm\n",
      "Processing: crawl/tx-houston-1.htm\n",
      "Processing: crawl/tx-houston-10.htm\n",
      "Processing: crawl/tx-houston-11.htm\n",
      "Processing: crawl/tx-houston-2.htm\n",
      "Processing: crawl/tx-houston-3.htm\n",
      "Processing: crawl/tx-houston-4.htm\n",
      "Processing: crawl/tx-houston-5.htm\n",
      "Processing: crawl/tx-houston-6.htm\n",
      "Processing: crawl/tx-houston-7.htm\n",
      "Processing: crawl/tx-houston-8.htm\n",
      "Processing: crawl/tx-houston-9.htm\n",
      "Processing: crawl/wa-seattle-1.htm\n",
      "Processing: crawl/wa-seattle-2.htm\n",
      "Processing: crawl/wa-seattle-3.htm\n",
      "Processing: crawl/wa-seattle-4.htm\n",
      "Processing: crawl/wa-seattle-5.htm\n",
      "Processing: crawl/wa-seattle-6.htm\n",
      "Processing: crawl/wa-seattle-7.htm\n",
      "Processing: crawl/wa-seattle-8.htm\n",
      "Processing: crawl/wa-seattle-9.htm\n"
     ]
    }
   ],
   "source": [
    "# Data extraction phase\n",
    "\n",
    "times = []\n",
    "fees = []\n",
    "reviews = []\n",
    "repeats = []\n",
    "city = []\n",
    "service = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "\n",
    "for src in os.listdir(datadir):\n",
    "    filename = datadir + src\n",
    "    print 'Processing: ' + filename\n",
    "    f = open(filename, 'r')\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "    soup = BeautifulSoup(data)\n",
    "    sitters = soup.findAll('div', {'class': 'card-content'})\n",
    "    for sitter in sitters:\n",
    "        rtwrap = sitter.findAll('div', {'class': 'icon-wrapper'})\n",
    "        if len(rtwrap) > 0:\n",
    "            response_time = rtwrap[0].text.strip('\\n')[19:]\n",
    "        else:\n",
    "            response_time = -1\n",
    "        fee = sitter.findAll('div', {'class': 'price price--primary u-text-center'})\n",
    "        review = sitter.find('span', {'class': 'vcard-review'})\n",
    "        if review is not None and len(review) > 0:\n",
    "            review = int(review.text.replace('Reviews', '').replace('Review', '').strip())\n",
    "        else:\n",
    "            review = 0\n",
    "        repeat = sitter.findAll('div', {'class': 'icon-wrapper'})\n",
    "        if len(repeat) == 2:\n",
    "            repeat = repeat[1].text.strip('\\n')[1]\n",
    "        else:\n",
    "            repeat = 0\n",
    "        services = sitter.findAll('div', {'class': 'vcard-line-item'})\n",
    "        full_star = sitter.findAll('i', {'class': 'ck-star'})\n",
    "        ratings = len(full_star)\n",
    "        half_star = sitter.findAll('i', {'class': 'ck-star-half'})\n",
    "        if len(half_star) > 0:\n",
    "            ratings += .5\n",
    "        fees.append(fee[0].text.strip('\\n$')[:2])\n",
    "        city.append(v)\n",
    "        times.append(response_time)\n",
    "        reviews.append(review)\n",
    "        repeats.append(repeat)\n",
    "        service.append(services[-1].text.strip('\\n'))\n",
    "        rating.append(ratings)\n",
    "\n",
    "df = pd.DataFrame({'city': city, 'fee': fees, 'response_time': times, 'review' : reviews, 'repeat' : repeats, 'services' : service, 'ratings': rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_datascience": {},
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3089, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_datascience": {},
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>fee</th>\n",
       "      <th>ratings</th>\n",
       "      <th>repeat</th>\n",
       "      <th>response_time</th>\n",
       "      <th>review</th>\n",
       "      <th>services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minneapolis</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Few Days</td>\n",
       "      <td>20</td>\n",
       "      <td>Boarding, Sitting, Daycare, Checkups and Visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minneapolis</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Few Hours</td>\n",
       "      <td>0</td>\n",
       "      <td>Boarding, Bathing, and Pick up and Drop off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minneapolis</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Day</td>\n",
       "      <td>9</td>\n",
       "      <td>Boarding and Pick up and Drop off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>minneapolis</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Few Hours</td>\n",
       "      <td>4</td>\n",
       "      <td>Boarding and Daycare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minneapolis</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Few Hours</td>\n",
       "      <td>0</td>\n",
       "      <td>Boarding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city fee  ratings repeat                      response_time  review  \\\n",
       "0  minneapolis  20        5      6   Few Days                              20   \n",
       "1  minneapolis  31        0      0  Few Hours                               0   \n",
       "2  minneapolis  25        5      4        Day                               9   \n",
       "3  minneapolis  25        5      4  Few Hours                               4   \n",
       "4  minneapolis  25        0      0  Few Hours                               0   \n",
       "\n",
       "                                            services  \n",
       "0  Boarding, Sitting, Daycare, Checkups and Visit...  \n",
       "1        Boarding, Bathing, and Pick up and Drop off  \n",
       "2                  Boarding and Pick up and Drop off  \n",
       "3                               Boarding and Daycare  \n",
       "4                                           Boarding  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_datascience": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAVE TO CSV FILE\n",
    "\n",
    "df.to_csv('dog-vacay.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "_datascience": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
